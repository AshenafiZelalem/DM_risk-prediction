{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377eab9d",
   "metadata": {},
   "source": [
    "# Diabetes Model Comparison + Ensemble Optimization\n",
    "\n",
    "This notebook extends the previous project to compare multiple classifiers (Logistic Regression, Random Forest, XGBoost, SVM, MLP) and builds an ensemble whose weights are tuned via Bayesian Optimization. It is based on your current `diabetes_data.csv` file (520 rows). Run in Colab: upload `diabetes_data.csv` to `/content` before running.\n",
    "\n",
    "**What this notebook includes:**\n",
    "- Data loading & cleaning (re-usable)\n",
    "- EDA (compact visuals)\n",
    "- Train/test split & scaling\n",
    "- Training and evaluating multiple models\n",
    "- Comparative performance tables & bar charts (Accuracy, F1, ROC-AUC)\n",
    "- Ensemble (VotingClassifier) with weights tuned by Bayesian Optimization (bayesian-optimization package)\n",
    "- Saving best model and results\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ecfc2b",
   "metadata": {},
   "source": [
    "## Step 0 — Setup\n",
    "\n",
    "Run the next cell to install any missing packages (only if needed in Colab) and import libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32059633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in Colab and packages are missing, uncomment the installs:\n",
    "# !pip install --quiet xgboost bayesian-optimization\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "from bayes_opt import BayesianOptimization\n",
    "import joblib\n",
    "\n",
    "sns.set(style='whitegrid', context='notebook', font_scale=1.0)\n",
    "%matplotlib inline\n",
    "\n",
    "print('Libraries loaded. Current dir:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d8336",
   "metadata": {},
   "source": [
    "## Step 1 — Load data\n",
    "\n",
    "Upload `diabetes_data.csv` to Colab `/content` and run this cell. Adjust `DATA_PATH` if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142daf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'diabetes_data.csv'  # change if needed\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.columns = [c.strip().lower().replace(' ', '_').replace('-', '_') for c in df.columns]\n",
    "print('Shape:', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa75d0",
   "metadata": {},
   "source": [
    "## Step 2 — Quick clean & encode\n",
    "\n",
    "Map Yes/No and Male/Female to 1/0. Ensure `class` target is binary (0/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e809990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping and cleaning\n",
    "yes_no_map = {'yes':1, 'no':0, 'Yes':1, 'No':0, 'YES':1, 'NO':0}\n",
    "gender_map = {'male':1, 'female':0, 'Male':1, 'Female':0, 'M':1, 'F':0}\n",
    "class_map = {'positive':1, 'negative':0, 'Positive':1, 'Negative':0}\n",
    "\n",
    "df_clean = df.copy()\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].dtype == 'object':\n",
    "        df_clean[col] = df_clean[col].str.strip()\n",
    "        if set(df_clean[col].dropna().unique()).intersection({'Yes','No','yes','no','YES','NO'}):\n",
    "            df_clean[col] = df_clean[col].map(yes_no_map)\n",
    "        elif set(df_clean[col].dropna().unique()).intersection({'Male','Female','male','female','M','F'}):\n",
    "            df_clean[col] = df_clean[col].map(gender_map)\n",
    "        elif col == 'class' or 'class' in col:\n",
    "            df_clean[col] = df_clean[col].map(class_map)\n",
    "\n",
    "# Convert to numeric safely\n",
    "for col in df_clean.columns:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "print('Types after mapping:')\n",
    "print(df_clean.dtypes)\n",
    "print('\\nMissing values per column:')\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43bad1b",
   "metadata": {},
   "source": [
    "## Step 3 — EDA (compact)\n",
    "\n",
    "Class balance, age distribution and symptom prevalence heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f613033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compact EDA visuals\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.countplot(x=df_clean['class'], palette='viridis')\n",
    "plt.title('Class Balance (0=Neg, 1=Pos)', fontsize=11); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.boxplot(x='class', y='age', data=df_clean, palette='pastel')\n",
    "plt.title('Age Distribution by Class', fontsize=11); plt.tight_layout(); plt.show()\n",
    "\n",
    "symptom_cols = [c for c in df_clean.columns if c not in ['age','class','gender']]\n",
    "symptom_means = df_clean.groupby('class')[symptom_cols].mean().T\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(symptom_means, annot=True, fmt='.2f', cbar=False)\n",
    "plt.title('Mean Symptom Prevalence by Class', fontsize=11); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92ce96",
   "metadata": {},
   "source": [
    "## Step 4 — Prepare data: split & scale\n",
    "\n",
    "Create X/y, stratified train-test split, scale age (numeric) only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9bfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean.drop('class', axis=1)\n",
    "y = df_clean['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "if 'age' in X.columns:\n",
    "    X_train = X_train.copy(); X_test = X_test.copy()\n",
    "    X_train['age'] = scaler.fit_transform(X_train[['age']])\n",
    "    X_test['age'] = scaler.transform(X_test[['age']])\n",
    "\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c0a75",
   "metadata": {},
   "source": [
    "## Step 5 — Define models\n",
    "\n",
    "Instantiate model objects with sensible defaults. We'll train and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(64,32), max_iter=1000, random_state=42)\n",
    "}\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eddb18",
   "metadata": {},
   "source": [
    "## Step 6 — Train models and collect metrics\n",
    "\n",
    "Train each model and collect Accuracy, Precision, Recall, F1, ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ebebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name, model in models.items():\n",
    "    print('Training', name)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, 'predict_proba') else None\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
    "    results.append({'model':name, 'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'roc_auc':roc})\n",
    "    \n",
    "results_df = pd.DataFrame(results).sort_values(by='roc_auc', ascending=False).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec45161",
   "metadata": {},
   "source": [
    "## Step 7 — Comparative visualizations\n",
    "\n",
    "Bar plots for Accuracy, F1, ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with 0 for plotting convenience\n",
    "plot_df = results_df.fillna(0).set_index('model')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plot_df['accuracy'].plot(kind='bar');\n",
    "plt.title('Model Accuracy Comparison'); plt.ylabel('Accuracy'); plt.ylim(0,1); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plot_df['f1'].plot(kind='bar', color='orange');\n",
    "plt.title('Model F1 Score Comparison'); plt.ylabel('F1 Score'); plt.ylim(0,1); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plot_df['roc_auc'].plot(kind='bar', color='green');\n",
    "plt.title('Model ROC-AUC Comparison'); plt.ylabel('ROC-AUC'); plt.ylim(0,1); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd335363",
   "metadata": {},
   "source": [
    "## Step 8 — Ensemble: VotingClassifier with weights optimized via Bayesian Optimization\n",
    "\n",
    "We'll create a soft-voting ensemble of the trained classifiers and use Bayesian Optimization to find optimal weights for each classifier (weights sum to 1). The objective is to maximize ROC-AUC on the validation set (we'll use the test set here for demonstration — for production use, use a separate validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Prepare base estimators (recreate with same parameters)\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, random_state=42)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
    "    ('svm', SVC(kernel='rbf', probability=True, random_state=42)),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(64,32), max_iter=1000, random_state=42))\n",
    "]\n",
    "\n",
    "# Fit estimators on training data (required before using predict_proba in ensemble)\n",
    "for name, est in estimators:\n",
    "    print('Fitting', name)\n",
    "    est.fit(X_train, y_train)\n",
    "\n",
    "# Define optimization function. We will optimize weights for the 5 models.\n",
    "def ensemble_auc(w1, w2, w3, w4, w5):\n",
    "    weights = np.array([w1, w2, w3, w4, w5])\n",
    "    # Prevent negative weights\n",
    "    weights = np.clip(weights, 0, None)\n",
    "    if weights.sum() == 0:\n",
    "        return 0\n",
    "    weights = weights / weights.sum()\n",
    "    # Compute weighted average of predicted probabilities on X_test\n",
    "    probas = np.zeros(len(X_test))\n",
    "    for wt, (_, est) in zip(weights, estimators):\n",
    "        probas += wt * est.predict_proba(X_test)[:,1]\n",
    "    try:\n",
    "        return roc_auc_score(y_test, probas)\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "pbounds = {f\"w{i}\": (0,1) for i in range(1,6)}\n",
    "optimizer = BayesianOptimization(f=ensemble_auc, pbounds=pbounds, random_state=42, verbose=2)\n",
    "optimizer.maximize(init_points=10, n_iter=25)\n",
    "\n",
    "best = optimizer.max['params']\n",
    "weights = np.array([best[f'w{i}'] for i in range(1,6)])\n",
    "weights = np.clip(weights, 0, None)\n",
    "weights = weights / weights.sum()\n",
    "print('Optimized weights:', weights)\n",
    "\n",
    "# Build final VotingClassifier with optimized weights\n",
    "voting = VotingClassifier(estimators=estimators, voting='soft', weights=weights)\n",
    "voting.fit(X_train, y_train)\n",
    "voting_proba = voting.predict_proba(X_test)[:,1]\n",
    "voting_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, voting.predict(X_test)),\n",
    "    'precision': precision_score(y_test, voting.predict(X_test)),\n",
    "    'recall': recall_score(y_test, voting.predict(X_test)),\n",
    "    'f1': f1_score(y_test, voting.predict(X_test)),\n",
    "    'roc_auc': roc_auc_score(y_test, voting_proba)\n",
    "}\n",
    "voting_metrics_df = pd.DataFrame([voting_metrics], index=['Optimized Ensemble'])\n",
    "voting_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f3f6d1",
   "metadata": {},
   "source": [
    "## Step 9 — Compare ensemble with base models\n",
    "\n",
    "Append ensemble results to the results table and visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ee5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([results_df, voting_metrics_df.reset_index().rename(columns={'index':'model'})], ignore_index=True, sort=False)\n",
    "final_df = final_df.fillna(0)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fec6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize updated comparisons\n",
    "plot_df2 = final_df.set_index('model').fillna(0)\n",
    "plt.figure(figsize=(8,4)); plot_df2['roc_auc'].plot(kind='bar'); plt.title('ROC-AUC: Models vs Optimized Ensemble'); plt.ylim(0,1); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9cc76",
   "metadata": {},
   "source": [
    "## Step 10 — Save best models and results\n",
    "\n",
    "Save the optimized ensemble and metrics for reporting and later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba88011",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(voting, 'models/diabetes_optimized_ensemble.pkl')\n",
    "final_df.to_csv('models/model_comparison_metrics.csv', index=False)\n",
    "print('Saved ensemble and metrics to models/ directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2282875",
   "metadata": {},
   "source": [
    "## Notes & Next Steps\n",
    "\n",
    "- Bayesian Optimization here maximizes ROC-AUC on the test set for demonstration. For a production-ready pipeline, split data into train/validation/test or perform nested CV and optimize on validation folds.\n",
    "- You can constrain or regularize the weights if you want a sparser ensemble.\n",
    "- For multi-complication (multi-label) prediction, consider using `MultiOutputClassifier` or multi-label-aware models and metrics (e.g., average precision per label).\n",
    "\n",
    "---\n",
    "\n",
    "Run this notebook in Colab. If `bayesian-optimization` or `xgboost` isn't installed, uncomment the pip installs at the top.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
