{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6038c4f",
   "metadata": {},
   "source": [
    "# Early-Stage Diabetes Risk Prediction\n",
    "\n",
    "**Project objective:** Build a model to predict early-stage diabetes using simple clinical features. This notebook includes step-by-step teaching notes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75b004",
   "metadata": {},
   "source": [
    "## Step 0 — Setup\n",
    "\n",
    "Run the next cell to import required packages. If a package is missing in Colab, uncomment the pip install line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99804089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet seaborn scikit-learn\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "sns.set(style='whitegrid')\n",
    "%matplotlib inline\n",
    "print('Packages loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e554a6b",
   "metadata": {},
   "source": [
    "## Step 1 — Load data\n",
    "\n",
    "Place `diabetes_data.csv` in the same folder and run the cell below. If using Colab, upload the file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff65b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'diabetes_data.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Rows,Cols:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f9cf3b",
   "metadata": {},
   "source": [
    "## Step 2 — Inspect & Clean\n",
    "\n",
    "Standardize column names and inspect unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names\n",
    "cols = [c.strip().lower().replace(' ', '_').replace('-', '_') for c in df.columns]\n",
    "df.columns = cols\n",
    "print('Columns:', cols)\n",
    "print('\\nMissing values:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6fb29",
   "metadata": {},
   "source": [
    "## Step 3 — Encode categorical variables\n",
    "\n",
    "Map Yes/No to 1/0, Male/Female to 1/0, and class to 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappings\n",
    "yes_no_map = {'yes':1, 'no':0, 'Yes':1, 'No':0, 'YES':1, 'NO':0}\n",
    "gender_map = {'male':1, 'female':0, 'Male':1, 'Female':0, 'M':1, 'F':0}\n",
    "class_map = {'positive':1, 'negative':0, 'Positive':1, 'Negative':0}\n",
    "\n",
    "df_clean = df.copy()\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].dtype == 'object':\n",
    "        # strip spaces\n",
    "        df_clean[col] = df_clean[col].str.strip()\n",
    "        if set(df_clean[col].dropna().unique()).intersection({'Yes','No','yes','no','YES','NO'}):\n",
    "            df_clean[col] = df_clean[col].map(yes_no_map)\n",
    "        elif set(df_clean[col].dropna().unique()).intersection({'Male','Female','male','female','M','F'}):\n",
    "            df_clean[col] = df_clean[col].map(gender_map)\n",
    "        elif col == 'class' or 'class' in col:\n",
    "            df_clean[col] = df_clean[col].map(class_map)\n",
    "\n",
    "print('Types after mapping:')\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d998d0",
   "metadata": {},
   "source": [
    "## Step 4 — Handle missing values\n",
    "\n",
    "Convert columns to numeric where possible and impute simple missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_clean.columns:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "print('Missing before impute:\\n', df_clean.isnull().sum())\n",
    "\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        if df_clean[col].dropna().isin([0,1]).all():\n",
    "            df_clean[col] = df_clean[col].fillna(0)\n",
    "        else:\n",
    "            df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "print('Missing after impute:\\n', df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84f25a",
   "metadata": {},
   "source": [
    "## Step 5 — EDA\n",
    "\n",
    "Plot class balance, age distribution, and symptom prevalence heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df_clean['class'])\n",
    "plt.title('Class balance (0=Neg,1=Pos)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x=df_clean['class'], y=df_clean['age'])\n",
    "plt.title('Age by class')\n",
    "plt.show()\n",
    "\n",
    "symptom_cols = [c for c in df_clean.columns if c not in ['age','class','gender']]\n",
    "symptom_means = df_clean.groupby('class')[symptom_cols].mean().T\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(symptom_means, annot=True, fmt='.2f')\n",
    "plt.title('Mean symptom prevalence by class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd3986",
   "metadata": {},
   "source": [
    "## Step 6 — Prepare data and split\n",
    "\n",
    "Scale age and do a stratified train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424dd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean.drop('class', axis=1)\n",
    "y = df_clean['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "if 'age' in X.columns:\n",
    "    X_train = X_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "    X_train['age'] = scaler.fit_transform(X_train[['age']])\n",
    "    X_test['age'] = scaler.transform(X_test[['age']])\n",
    "\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7526c99",
   "metadata": {},
   "source": [
    "## Step 7 — Train models\n",
    "\n",
    "Fit Logistic Regression and Random Forest, then evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a844a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_proba_lr = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "def evaluate(y_true, y_pred, y_proba):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_proba)\n",
    "    }\n",
    "\n",
    "lr_metrics = evaluate(y_test, y_pred_lr, y_proba_lr)\n",
    "rf_metrics = evaluate(y_test, y_pred_rf, y_proba_rf)\n",
    "pd.DataFrame([lr_metrics, rf_metrics], index=['LogisticRegression','RandomForest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde42752",
   "metadata": {},
   "source": [
    "## Step 8 — Confusion matrices & ROC\n",
    "\n",
    "Visualize confusion matrices and ROC curves for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae749829",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d', ax=axes[0])\n",
    "axes[0].set_title('LR Confusion Matrix')\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', ax=axes[1])\n",
    "axes[1].set_title('RF Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'LR AUC={lr_metrics[\"roc_auc\"]:.3f}')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'RF AUC={rf_metrics[\"roc_auc\"]:.3f}')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656bfc0",
   "metadata": {},
   "source": [
    "## Step 9 — Interpretability\n",
    "\n",
    "Show Random Forest importances and permutation importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values()\n",
    "plt.figure(figsize=(8,6))\n",
    "imp.tail(15).plot(kind='barh')\n",
    "plt.title('RF Feature Importances')\n",
    "plt.show()\n",
    "\n",
    "perm = permutation_importance(rf, X_test, y_test, n_repeats=20, random_state=42)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X.columns).sort_values()\n",
    "plt.figure(figsize=(8,6))\n",
    "perm_imp.tail(15).plot(kind='barh')\n",
    "plt.title('Permutation Importance (RF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f1a8b8",
   "metadata": {},
   "source": [
    "## Step 10 — Save outputs & next steps\n",
    "\n",
    "Save cleaned data and model metrics. Next: hyperparameter tuning, CV, SHAP, and a Power BI dashboard showing predicted risk by patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('outputs', exist_ok=True)\n",
    "df_clean.to_csv('outputs/data_clean.csv', index=False)\n",
    "pd.DataFrame([lr_metrics, rf_metrics], index=['LogisticRegression','RandomForest']).to_csv('outputs/model_metrics.csv')\n",
    "print('Saved outputs to outputs/')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
